const axios = require('axios');
const fs = require('fs');
const gtts = require('gtts');

async function formatFont(text) {
  const fontMapping = {
    a: "ð–º", b: "ð–»", c: "ð–¼", d: "ð–½", e: "ð–¾", f: "ð–¿", g: "ð—€", h: "ð—", i: "ð—‚", j: "ð—ƒ", k: "ð—„", l: "ð—…", m: "ð—†",
    n: "ð—‡", o: "ð—ˆ", p: "ð—‰", q: "ð—Š", r: "ð—‹", s: "ð—Œ", t: "ð—", u: "ð—Ž", v: "ð—", w: "ð—", x: "ð—‘", y: "ð—’", z: "ð—“",
    A: "ð– ", B: "ð–¡", C: "ð–¢", D: "ð–£", E: "ð–¤", F: "ð–¥", G: "ð–¦", H: "ð–§", I: "ð–¨", J: "ð–©", K: "ð–ª", L: "ð–«", M: "ð–¬",
    N: "ð–­", O: "ð–®", P: "ð–¯", Q: "ð–°", R: "ð–±", S: "ð–²", T: "ð–³", U: "ð–´", V: "ð–µ", W: "ð–¶", X: "ð–·", Y: "ð–¸", Z: "ð–¹"
  };

  let formattedText = "";
  for (const char of text) {
    if (char in fontMapping) {
      formattedText += fontMapping[char];
    } else {
      formattedText += char;
    }
  }

  return formattedText;
}

async function convertImageToText(imageURL) {
  try {
    const response = await axios.get(`https://img2txt-bien.vercel.app/api/recognition?image=${encodeURIComponent(imageURL)}`);
    return response.data.extractedText;
  } catch (error) {
    console.error(error);
    return null;
  }
}

module.exports = {
  config: {
    name: "Demo",
    aliases: [],
    version: "2.1.3",
    author: "Hazeyy",
    role: 0,
    category: "no prefix",
    shortDescription: {
      en: "GPT-4 Voice x Image recognition",
      vi: "GPT-4 Giá»ng nÃ³i x Nháº­n dáº¡ng áº£nh"
    },
    longDescription: {
      en: "This command uses GPT-4 to interact with text inputs and image recognition.",
      vi: "Lá»‡nh nÃ y sá»­ dá»¥ng GPT-4 Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vá»›i Ä‘áº§u vÃ o vÄƒn báº£n vÃ  nháº­n dáº¡ng áº£nh."
    },
    guide: {
      en: "( Model-v3 Demo GPT-4 )",
      vi: "( Model-v3 Demo GPT-4 )"
    }
  },
  onStart: async ({ event, args, message, usersData, api, commandName }) => {
    if (!(event.body.startsWith("demo") || event.body.startsWith("Demo"))) return;

    const { threadID, messageID, type, messageReply, body } = event;

    let question = '';
    let hasImage = false;

    if (type === 'message_reply') {
      if (messageReply?.attachments[0]?.type === 'photo') {
        hasImage = true;
        const attachment = messageReply.attachments[0];
        const imageURL = attachment.url;
        question = await convertImageToText(imageURL);

        if (!question) {
          api.sendMessage('â— ð–´ð—‡ð–ºð–»ð—…ð–¾ ð—ð—ˆ ð–¼ð—ˆð—‡ð—ð–¾ð—‹ð— ð—ð—ð—‚ð—Œ ð—‚ð—†ð–ºð—€ð–¾.', threadID, messageID);
          return;
        }
      } else {
        question = messageReply?.body?.trim() || '';
      }
    } else {
      question = body.slice(5).trim();
    }

    if (!question) {
      api.sendMessage("HelloðŸ‘‹, I am Model-v3 Demo GPT-4. How can I assist you today?", event.threadID);
      return;
    }

    try {
      api.sendTypingIndicator(event.threadID);
      api.sendMessage('ðŸ—¨ï¸ | Demo GPT-4 is thinking...', event.threadID);

      const response = await axios.get(`https://llama3-8b-8192.vercel.app/?ask=${encodeURIComponent(question)}`);
      const reply = response.data.reply;

      if (reply.trim() !== "") {
        const formattedReply = await formatFont(reply);
        const gttsService = new gtts(formattedReply, 'en');
        gttsService.save('gpt4_response.mp3', function () {
          api.sendMessage(`ðŸ¤– GPT-4 (Demo)\n\nðŸ—¨ï¸: ${formattedReply}\n\nI hope it helps âœ¨`, event.threadID);
          api.sendMessage({
            attachment: fs.createReadStream('gpt4_response.mp3'),
            body: 'ðŸ”Š Demo GPT-4 (Voice)',
            mentions: [{ tag: 'GPT-4 Response', id: api.getCurrentUserID() }]
          }, event.threadID);
        });
      } else {
        api.sendMessage("ðŸ¤– Demo GPT-4 couldn't provide a response to your query.", event.threadID);
      }
    } catch (error) {
      console.error(error);
      api.sendMessage("ðŸ”´ An error occurred. Please try again later.", event.threadID);
    }
  },
  onReply: async ({ api, event, message, args, commandName, usersData, Reply }) => {
    // Additional code if needed for replies
  },
  onChat: async ({ api, event, message, args, commandName, usersData }) => {
    // Additional code if needed for general chat interactions
  }
};
